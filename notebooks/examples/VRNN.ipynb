{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "# add to path\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import attr\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import seaborn\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "\n",
    "tf.config.set_visible_devices([], 'GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sonnet as snt\n",
    "\n",
    "from filterflow.smc import SMC\n",
    "from filterflow.base import State, StateWithMemory, StateSeries, DTYPE_TO_STATE_SERIES\n",
    "\n",
    "from filterflow.observation.base import ObservationModelBase, ObservationSampler\n",
    "from filterflow.observation.linear import LinearObservationSampler\n",
    "from filterflow.transition.random_walk import RandomWalkModel\n",
    "from filterflow.proposal import BootstrapProposalModel\n",
    "from filterflow.transition.base import TransitionModelBase\n",
    "\n",
    "from filterflow.resampling.criterion import NeffCriterion, AlwaysResample, NeverResample\n",
    "from filterflow.resampling.standard import SystematicResampler, MultinomialResampler\n",
    "from filterflow.resampling.differentiable import RegularisedTransform, CorrectedRegularizedTransform, PartiallyCorrectedRegularizedTransform\n",
    "\n",
    "from filterflow.resampling.base import NoResampling\n",
    "\n",
    "from filterflow.state_space_model import StateSpaceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "data_dir = \"../../data/piano_data\"\n",
    "\n",
    "def sparse_pianoroll_to_dense(pianoroll, min_note, num_notes):\n",
    "    \"\"\"Converts a sparse pianoroll to a dense numpy array.\n",
    "    Given a sparse pianoroll, converts it to a dense numpy array of shape\n",
    "    [num_timesteps, num_notes] where entry i,j is 1.0 if note j is active on\n",
    "    timestep i and 0.0 otherwise.\n",
    "    Args:\n",
    "    pianoroll: A sparse pianoroll object, a list of tuples where the i'th tuple\n",
    "      contains the indices of the notes active at timestep i.\n",
    "    min_note: The minimum note in the pianoroll, subtracted from all notes so\n",
    "      that the minimum note becomes 0.\n",
    "    num_notes: The number of possible different note indices, determines the\n",
    "      second dimension of the resulting dense array.\n",
    "    Returns:\n",
    "    dense_pianoroll: A [num_timesteps, num_notes] numpy array of floats.\n",
    "    num_timesteps: A python int, the number of timesteps in the pianoroll.\n",
    "    \"\"\"\n",
    "    num_timesteps = len(pianoroll)\n",
    "    inds = []\n",
    "    for time, chord in enumerate(pianoroll):\n",
    "        # Re-index the notes to start from min_note.\n",
    "        inds.extend((time, note-min_note) for note in chord)\n",
    "        shape = [num_timesteps, num_notes]\n",
    "    values = [1.] * len(inds)\n",
    "    sparse_pianoroll = coo_matrix(\n",
    "      (values, ([x[0] for x in inds], [x[1] for x in inds])),\n",
    "      shape=shape)\n",
    "    return sparse_pianoroll.toarray(), num_timesteps\n",
    "\n",
    "def create_pianoroll_dataset(path,\n",
    "                             split,\n",
    "                             batch_size,\n",
    "                             num_parallel_calls=4,\n",
    "                             shuffle=False,\n",
    "                             repeat=False,\n",
    "                             min_note=21,\n",
    "                             max_note=108):\n",
    "    \"\"\"Creates a pianoroll dataset.\n",
    "    Args:\n",
    "    path: The path of a pickle file containing the dataset to load.\n",
    "    split: The split to use, can be train, test, or valid.\n",
    "    batch_size: The batch size. If repeat is False then it is not guaranteed\n",
    "      that the true batch size will match for all batches since batch_size\n",
    "      may not necessarily evenly divide the number of elements.\n",
    "    num_parallel_calls: The number of threads to use for parallel processing of\n",
    "      the data.\n",
    "    shuffle: If true, shuffles the order of the dataset.\n",
    "    repeat: If true, repeats the dataset endlessly.\n",
    "    min_note: The minimum note number of the dataset. For all pianoroll datasets\n",
    "      the minimum note is number 21, and changing this affects the dimension of\n",
    "      the data. This is useful mostly for testing.\n",
    "    max_note: The maximum note number of the dataset. For all pianoroll datasets\n",
    "      the maximum note is number 108, and changing this affects the dimension of\n",
    "      the data. This is useful mostly for testing.\n",
    "    Returns:\n",
    "    inputs: A batch of input sequences represented as a dense Tensor of shape\n",
    "      [time, batch_size, data_dimension]. The sequences in inputs are the\n",
    "      sequences in targets shifted one timestep into the future, padded with\n",
    "      zeros. This tensor is mean-centered, with the mean taken from the pickle\n",
    "      file key 'train_mean'.\n",
    "    targets: A batch of target sequences represented as a dense Tensor of\n",
    "      shape [time, batch_size, data_dimension].\n",
    "    lens: An int Tensor of shape [batch_size] representing the lengths of each\n",
    "      sequence in the batch.\n",
    "    mean: A float Tensor of shape [data_dimension] containing the mean loaded\n",
    "      from the pickle file.\n",
    "    \"\"\"\n",
    "    # Load the data from disk.\n",
    "    num_notes = max_note - min_note + 1\n",
    "    with tf.io.gfile.GFile(path, \"rb\") as f:\n",
    "        raw_data = pickle.load(f)\n",
    "    pianorolls = raw_data[split]\n",
    "    mean = raw_data[\"train_mean\"]\n",
    "    num_examples = len(pianorolls)\n",
    "\n",
    "    def pianoroll_generator():\n",
    "        for sparse_pianoroll in pianorolls:\n",
    "            yield sparse_pianoroll_to_dense(sparse_pianoroll, min_note, num_notes)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_generator(\n",
    "      pianoroll_generator,\n",
    "      output_types=(tf.float64, tf.int64),\n",
    "      output_shapes=([None, num_notes], []))\n",
    "\n",
    "    if repeat: \n",
    "        dataset = dataset.repeat()\n",
    "    if shuffle: \n",
    "        dataset = dataset.shuffle(num_examples)\n",
    "\n",
    "    # Batch sequences togther, padding them to a common length in time.\n",
    "    dataset = dataset.padded_batch(batch_size,\n",
    "                                 padded_shapes=([None, num_notes], []))\n",
    "\n",
    "    def process_pianoroll_batch(data, lengths):\n",
    "        \"\"\"Create mean-centered and time-major next-step prediction Tensors.\"\"\"\n",
    "        data = tf.cast(tf.transpose(data, perm=[1, 0, 2]), float)\n",
    "        lengths = tf.cast(lengths, tf.int32)\n",
    "        targets = data\n",
    "        # Mean center the inputs.\n",
    "        inputs = data - tf.constant(mean, dtype=tf.float32,\n",
    "                                    shape=[1, 1, mean.shape[0]])\n",
    "        # Shift the inputs one step forward in time. Also remove the last timestep\n",
    "        # so that targets and inputs are the same length.\n",
    "        inputs = tf.pad(inputs, [[1, 0], [0, 0], [0, 0]], mode=\"CONSTANT\")[:-1]\n",
    "        # Mask out unused timesteps.\n",
    "        inputs *= tf.expand_dims(tf.transpose(\n",
    "            tf.sequence_mask(lengths, dtype=inputs.dtype)), 2)\n",
    "        return inputs, targets, lengths\n",
    "\n",
    "    dataset = dataset.map(process_pianoroll_batch,\n",
    "                        num_parallel_calls=num_parallel_calls)\n",
    "    dataset = dataset.prefetch(num_examples)\n",
    "\n",
    "    itr = tf.compat.v1.data.make_one_shot_iterator(dataset)\n",
    "    inputs, targets, lengths = itr.get_next()\n",
    "    return inputs, targets, lengths, tf.constant(mean, dtype=tf.float32)\n",
    "\n",
    "path = os.path.join(data_dir, 'jsb.pkl')\n",
    "inputs_tensor, targets_tensor, lens, mean = create_pianoroll_dataset(path, split='train', batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "T = targets_tensor.shape.as_list()[0]\n",
    "observation_size = targets_tensor.shape.as_list()[-1]\n",
    "\n",
    "\n",
    "latent_size = 10\n",
    "fcnet_hidden_sizes = [latent_size]\n",
    "encoded_data_size = latent_size\n",
    "rnn_hidden_size = latent_size//2\n",
    "\n",
    "latent_encoder_layers = [32]\n",
    "latent_encoded_size = 32\n",
    "\n",
    "latent_encoder = snt.nets.MLP(\n",
    "            output_sizes=latent_encoder_layers + [latent_encoded_size],\n",
    "            name=\"latent_encoder\")\n",
    "\n",
    "data_encoder_layers = [32]\n",
    "encoded_data_size = 32\n",
    "data_encoder = snt.nets.MLP(\n",
    "            output_sizes=data_encoder_layers + [encoded_data_size],\n",
    "            name=\"data_encoder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store observations\n",
    "batch_size = 1\n",
    "n_particles = 100\n",
    "dimension = latent_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_tensor = tf.expand_dims(inputs_tensor, 1)\n",
    "targets_tensor = tf.expand_dims(targets_tensor, 1)\n",
    "\n",
    "obs_data = tf.data.Dataset.from_tensor_slices(targets_tensor)\n",
    "inputs_data = tf.data.Dataset.from_tensor_slices(inputs_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNNormalDistribution(tf.Module):\n",
    "    \"\"\"A Normal distribution with mean and var parametrised by NN\"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 size, \n",
    "                 hidden_layer_sizes, \n",
    "                 sigma_min=0.0,\n",
    "                 raw_sigma_bias=0.25, \n",
    "                 hidden_activation_fn=tf.nn.relu,\n",
    "                 name=\"conditional_normal_distribution\"):\n",
    "        \n",
    "        super(NNNormalDistribution, self).__init__(name=name)\n",
    "        \n",
    "        self.sigma_min = sigma_min\n",
    "        self.raw_sigma_bias = raw_sigma_bias\n",
    "        self.size = size\n",
    "        self.fcnet = snt.nets.MLP(\n",
    "            output_sizes=hidden_layer_sizes + [2*size],\n",
    "            activation=hidden_activation_fn,\n",
    "            activate_final=False,\n",
    "            name=name + \"_fcnet\")\n",
    "\n",
    "    def get_params(self, tensor_list, **unused_kwargs):\n",
    "        \"\"\"Computes the parameters of a normal distribution based on the inputs.\"\"\"\n",
    "        inputs = tf.concat(tensor_list, axis=-1)\n",
    "        outs = self.fcnet(inputs)\n",
    "        mu, sigma = tf.split(outs, 2, axis=-1)\n",
    "        sigma = tf.maximum(tf.nn.softplus(sigma + self.raw_sigma_bias), self.sigma_min)\n",
    "        return mu, sigma\n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        \"\"\"Creates a normal distribution conditioned on the inputs.\"\"\"\n",
    "        mu, sigma = self.get_params(args, **kwargs)\n",
    "        return tfp.distributions.Normal(loc=mu, scale=sigma)\n",
    "    \n",
    "class NNBernoulliDistribution(tf.Module):\n",
    "    \"\"\"A Normal distribution with mean and var parametrised by NN\"\"\"\n",
    "\n",
    "    def __init__(self, \n",
    "                 size, \n",
    "                 hidden_layer_sizes, \n",
    "                 hidden_activation_fn=tf.nn.relu,\n",
    "                 name=\"conditional_bernoulli_distribution\"):\n",
    "        super(NNBernoulliDistribution, self).__init__(name=name)\n",
    "        \n",
    "        self.size = size\n",
    "        self.fcnet = snt.nets.MLP(\n",
    "            output_sizes=hidden_layer_sizes + [size],\n",
    "            activation=hidden_activation_fn,\n",
    "            activate_final=tf.nn.sigmoid,\n",
    "            name=name + \"_fcnet\")\n",
    "\n",
    "    def get_logits(self, tensor_list, **unused_kwargs):\n",
    "        \"\"\"Computes the parameters of a normal distribution based on the inputs.\"\"\"\n",
    "        inputs = tf.concat(tensor_list, axis=-1)\n",
    "        return self.fcnet(inputs)\n",
    "        \n",
    "\n",
    "    def __call__(self, *args, **kwargs):\n",
    "        \"\"\"Creates a normal distribution conditioned on the inputs.\"\"\"\n",
    "        logits = self.get_logits(args, **kwargs)\n",
    "        return tfp.distributions.Bernoulli(logits=logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VRNNTransitionModel(TransitionModelBase):\n",
    "    def __init__(self, \n",
    "                 rnn_hidden_size, \n",
    "                 data_encoder, \n",
    "                 latent_encoder,\n",
    "                 name='NNTransitionModel'):\n",
    "        \n",
    "        super(VRNNTransitionModel, self).__init__(name=name)\n",
    "        \n",
    "        # mlp parametrised gaussian\n",
    "        self.transition = NNNormalDistribution(size=latent_size, \n",
    "                                               hidden_layer_sizes=[latent_size])\n",
    "        # encoder for inputs\n",
    "        self.latent_encoder = latent_encoder\n",
    "        \n",
    "        # lstm cell\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "#         self.rnn = tf.keras.layers.LSTM(rnn_hidden_size,\n",
    "#                                        return_sequences=True,\n",
    "#                                        return_state=True)\n",
    "        self.rnn = tf.keras.layers.LSTMCell(rnn_hidden_size)\n",
    "        \n",
    "    def run_rnn(self, state: State, inputs: tf.Tensor):\n",
    "        \n",
    "        tiled_inputs = tf.tile(inputs, [state.batch_size, state.n_particles, 1])\n",
    "        # process latent state\n",
    "        latent_state = state.particles\n",
    "        \n",
    "        # encode and reshape latent state\n",
    "        latent_encoded = self.latent_encoder(latent_state)\n",
    "        \n",
    "        B, N, D = latent_encoded.shape\n",
    "        # process rnn_state\n",
    "        rnn_state = tf.reshape(state.rnn_state, [B,  N, self.rnn_hidden_size*2])\n",
    "\n",
    "        rnn_state = tf.split(rnn_state, 2, axis=-1)\n",
    "        \n",
    "\n",
    "        # run rnn\n",
    "        rnn_inputs = tf.concat([tiled_inputs, latent_encoded], axis=-1)\n",
    "        rnn_inputs_reshaped = tf.reshape(rnn_inputs, (B*N, -1))\n",
    "        rnn_state_reshaped = [tf.reshape(elem, (B*N, -1)) for elem in rnn_state]\n",
    "        rnn_out, rnn_state = self.rnn(rnn_inputs_reshaped, rnn_state_reshaped)\n",
    "\n",
    "\n",
    "        rnn_state = tf.concat(rnn_state, axis=-1)\n",
    "        rnn_state = tf.reshape(rnn_state, [state.batch_size, state.n_particles, self.rnn_hidden_size*2])\n",
    "        rnn_out = tf.reshape(rnn_out, [state.batch_size, state.n_particles, self.rnn_hidden_size])\n",
    "        return rnn_out, rnn_state, latent_encoded\n",
    "    \n",
    "    def latent_dist(self, state, rnn_out):\n",
    "        dist = self.transition(rnn_out)\n",
    "        return dist\n",
    "\n",
    "    def loglikelihood(self, prior_state: State, proposed_state: State, inputs: tf.Tensor):\n",
    "        rnn_out, rnn_state, latent_encoded = self.run_rnn(prior_state, inputs)\n",
    "        dist = self.transition(rnn_out)\n",
    "        new_latent = proposed_state.particles\n",
    "        return tf.reduce_sum(dist.log_prob(new_latent), axis=-1)\n",
    "\n",
    "    def sample(self, state: State, inputs: tf.Tensor):\n",
    "        \n",
    "        rnn_out, rnn_state, latent_encoded = self.run_rnn(state, inputs)\n",
    "        dist = self.latent_dist(state, rnn_out)\n",
    "        latent_state = dist.sample()\n",
    "        \n",
    "        return VRNNState(particles=latent_state, \n",
    "                          log_weights = state.log_weights,\n",
    "                          weights=state.weights, \n",
    "                          log_likelihoods=state.log_likelihoods,\n",
    "                          rnn_state = rnn_state,\n",
    "                          rnn_out = rnn_out,\n",
    "                          latent_encoded =  latent_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VRNNProposalModel(VRNNTransitionModel):\n",
    "    def __init__(self, \n",
    "                 rnn_hidden_size, \n",
    "                 data_encoder, \n",
    "                 latent_encoder,\n",
    "                 name='VRNNProposalModel'):\n",
    "        \n",
    "        super(VRNNProposalModel, self).__init__(rnn_hidden_size, \n",
    "                 data_encoder, \n",
    "                 latent_encoder,name)\n",
    "\n",
    "    def loglikelihood(self, proposed_state: State, state: State, inputs: tf.Tensor, observation: tf.Tensor):\n",
    "        rnn_out, rnn_state, latent_encoded = self.run_rnn(state, inputs)\n",
    "        dist = self.latent_dist(state, rnn_out)\n",
    "        new_latent = proposed_state.particles\n",
    "        return tf.reduce_sum(dist.log_prob(new_latent), axis=-1)\n",
    "    \n",
    "    def propose(self, state: State, inputs: tf.Tensor, observation: tf.Tensor):\n",
    "        return self.sample(state, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VRNNNormalObservationModel(ObservationSampler):\n",
    "    \n",
    "    def __init__(self, latent_encoder, observation_size, name='VRNNObservationModel'):\n",
    "        super(VRNNNormalObservationModel, self).__init__(name=name)\n",
    "        # mlp parametrised gaussian\n",
    "        self.emission = NNNormalDistribution(size=observation_size, \n",
    "                                             hidden_layer_sizes=[observation_size])\n",
    "        \n",
    "    \n",
    "    def observation_dist(self, state: State):\n",
    "        latent_state = state.particles\n",
    "        latent_encoded = state.latent_encoded\n",
    "        rnn_out = state.rnn_out\n",
    "        dist = self.emission(latent_state, rnn_out) \n",
    "        return dist\n",
    "    \n",
    "    def loglikelihood(self, state: State, observation: tf.Tensor):\n",
    "        \n",
    "        dist = self.observation_dist(state)\n",
    "        return tf.reduce_sum(dist.log_prob(observation), axis=-1)\n",
    "        \n",
    "\n",
    "    def sample(self, state: State):\n",
    "        dist = self.observation_dist(state)\n",
    "        return dist.sample()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VRNNBernoulliObservationModel(ObservationSampler):\n",
    "    \n",
    "    def __init__(self, latent_encoder, observation_size, name='VRNNObservationModel'):\n",
    "        super(VRNNBernoulliObservationModel, self).__init__(name=name)\n",
    "        # mlp parametrised gaussian\n",
    "        self.emission = NNBernoulliDistribution(size=observation_size, \n",
    "                                                hidden_layer_sizes=[observation_size])\n",
    "        \n",
    "    \n",
    "    def observation_dist(self, state: State):\n",
    "        latent_state = state.particles\n",
    "        latent_encoded = state.latent_encoded\n",
    "        rnn_out = state.rnn_out\n",
    "        dist = self.emission(latent_state, rnn_out) \n",
    "        return dist\n",
    "    \n",
    "    def loglikelihood(self, state: State, observation: tf.Tensor):\n",
    "        dist = self.observation_dist(state)\n",
    "        return tf.reduce_sum(dist.log_prob(observation), axis=-1)\n",
    "        \n",
    "\n",
    "    def sample(self, state: State):\n",
    "        dist = self.observation_dist(state)\n",
    "        return dist.sample()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@attr.s\n",
    "class VRNNState(State):\n",
    "    ADDITIONAL_STATE_VARIABLES = ('rnn_state',) # rnn_out and encoded no need to be resampled\n",
    "    rnn_state = attr.ib(default=None)\n",
    "    rnn_out = attr.ib(default=None)\n",
    "    latent_encoded = attr.ib(default=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "transition_model = VRNNTransitionModel(rnn_hidden_size, data_encoder, latent_encoder)\n",
    "observation_model = VRNNBernoulliObservationModel(latent_encoder, observation_size)\n",
    "proposal_model = VRNNProposalModel(rnn_hidden_size, data_encoder, latent_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial state\n",
    "normal_dist = tfp.distributions.Normal(0., 1.)\n",
    "initial_latent_state = tf.zeros([batch_size, n_particles, dimension])\n",
    "initial_latent_state = tf.cast(initial_latent_state, dtype=float)\n",
    "latent_encoded = transition_model.latent_encoder(initial_latent_state)\n",
    "\n",
    "# initial rnn_state\n",
    "initial_rnn_state = [normal_dist.sample([batch_size,n_particles,rnn_hidden_size])]*2\n",
    "initial_rnn_state = tf.concat(initial_rnn_state, axis=-1)\n",
    "\n",
    "# rnn_out\n",
    "initial_rnn_out = tf.zeros([batch_size, n_particles, rnn_hidden_size])\n",
    "\n",
    "initial_weights = tf.ones((batch_size, n_particles), dtype=float) / tf.cast(n_particles, float)\n",
    "log_likelihoods = tf.zeros(batch_size, dtype=float)\n",
    "initial_state = VRNNState(particles=initial_latent_state, \n",
    "                          log_weights = tf.math.log(initial_weights),\n",
    "                          weights=initial_weights, \n",
    "                          log_likelihoods=log_likelihoods,\n",
    "                          rnn_state = initial_rnn_state,\n",
    "                          rnn_out = initial_rnn_out,\n",
    "                          latent_encoded = latent_encoded)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snt networks initiated on first call\n",
    "t_samp = transition_model.sample(initial_state, inputs_tensor[0])\n",
    "obs_samp = observation_model.sample(initial_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent_encoder/linear_0/b:0\n",
      "latent_encoder/linear_0/w:0\n",
      "latent_encoder/linear_1/b:0\n",
      "latent_encoder/linear_1/w:0\n",
      "lstm_cell/kernel:0\n",
      "lstm_cell/recurrent_kernel:0\n",
      "lstm_cell/bias:0\n",
      "conditional_normal_distribution_fcnet/linear_0/b:0\n",
      "conditional_normal_distribution_fcnet/linear_0/w:0\n",
      "conditional_normal_distribution_fcnet/linear_1/b:0\n",
      "conditional_normal_distribution_fcnet/linear_1/w:0\n"
     ]
    }
   ],
   "source": [
    "for var in transition_model.variables:\n",
    "    print(var.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional_bernoulli_distribution_fcnet/linear_0/b:0\n",
      "conditional_bernoulli_distribution_fcnet/linear_0/w:0\n",
      "conditional_bernoulli_distribution_fcnet/linear_1/b:0\n",
      "conditional_bernoulli_distribution_fcnet/linear_1/w:0\n"
     ]
    }
   ],
   "source": [
    "for var in observation_model.variables:\n",
    "    print(var.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particle Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resampling\n",
    "resampling_criterion = NeffCriterion(tf.constant(0.5), tf.constant(True))\n",
    "systematic = SystematicResampler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "particle_filter = SMC(observation_model, transition_model, proposal_model, resampling_criterion, systematic)\n",
    "recorded_states = particle_filter(initial_state, observation_series=obs_data, n_observations=T, inputs_series=inputs_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainable_variables = transition_model.variables + observation_model.variables\n",
    "init_values = [v.value() for v in trainable_variables]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "B, N = 4, 4\n",
    "\n",
    "# initial state\n",
    "normal_dist = tfp.distributions.Normal(0., 1.)\n",
    "initial_latent_state = tf.zeros([B, N, dimension])\n",
    "initial_latent_state = tf.cast(initial_latent_state, dtype=float)\n",
    "latent_encoded = transition_model.latent_encoder(initial_latent_state)\n",
    "\n",
    "# initial rnn_state\n",
    "initial_rnn_state = [normal_dist.sample([B, N, rnn_hidden_size])]*2\n",
    "initial_rnn_state = tf.concat(initial_rnn_state, axis=-1)\n",
    "\n",
    "# rnn_out\n",
    "initial_rnn_out = tf.zeros([B, N, rnn_hidden_size])\n",
    "\n",
    "initial_weights = tf.ones((B, N), dtype=float) / tf.cast(N, float)\n",
    "log_likelihoods = tf.zeros(B, dtype=float)\n",
    "\n",
    "init_state = VRNNState(particles=initial_latent_state, \n",
    "                          log_weights = tf.math.log(initial_weights),\n",
    "                          weights=initial_weights, \n",
    "                          log_likelihoods=log_likelihoods,\n",
    "                          rnn_state=initial_rnn_state,\n",
    "                          rnn_out=initial_rnn_out,\n",
    "                          latent_encoded=latent_encoded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "LARGE_B = 4\n",
    "\n",
    "# initial state\n",
    "large_initial_latent_state = tf.zeros([LARGE_B, N, dimension])\n",
    "large_initial_latent_state = tf.cast(large_initial_latent_state, dtype=float)\n",
    "large_latent_encoded = transition_model.latent_encoder(large_initial_latent_state)\n",
    "\n",
    "# initial rnn_state\n",
    "large_initial_rnn_state = [normal_dist.sample([LARGE_B, N, rnn_hidden_size])]*2\n",
    "large_initial_rnn_state = tf.concat(large_initial_rnn_state, axis=-1)\n",
    "\n",
    "# rnn_out\n",
    "large_initial_rnn_out = tf.zeros([LARGE_B, N, rnn_hidden_size])\n",
    "\n",
    "large_initial_weights = tf.ones((LARGE_B, N), dtype=float) / tf.cast(N, float)\n",
    "large_log_likelihoods = tf.zeros(LARGE_B, dtype=float)\n",
    "\n",
    "large_init_state = VRNNState(  particles=large_initial_latent_state, \n",
    "                                  log_weights = tf.math.log(large_initial_weights),\n",
    "                                  weights=large_initial_weights, \n",
    "                                  log_likelihoods=large_log_likelihoods,\n",
    "                                  rnn_state=large_initial_rnn_state,\n",
    "                                  rnn_out=large_initial_rnn_out,\n",
    "                                  latent_encoded=large_latent_encoded)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_proposal = BootstrapProposalModel(transition_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "resampling_criterion = NeffCriterion(tf.constant(0.5), tf.constant(True))\n",
    "resampling_method = MultinomialResampler()\n",
    "\n",
    "epsilon = tf.constant(0.5)\n",
    "scaling = tf.constant(0.75)\n",
    "\n",
    "regularized = RegularisedTransform(epsilon, scaling=scaling, max_iter=1000, convergence_threshold=1e-1)\n",
    "\n",
    "corrected = PartiallyCorrectedRegularizedTransform(regularized)\n",
    "\n",
    "    \n",
    "multinomial_smc = SMC(observation_model, transition_model, proposal_model, resampling_criterion, resampling_method)\n",
    "regularized_smc = SMC(observation_model, transition_model, proposal_model, resampling_criterion, regularized)\n",
    "corrected_smc = SMC(observation_model, transition_model, proposal_model, resampling_criterion, corrected)\n",
    "bootstrap_smc = SMC(observation_model, transition_model, bootstrap_proposal, resampling_criterion, resampling_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def smc_routine(smc, state, use_correction_term=False):\n",
    "    final_state = smc(state, obs_data, n_observations=T, inputs_series=inputs_data, return_final=True)\n",
    "    res = tf.reduce_mean(final_state.log_likelihoods)\n",
    "    if use_correction_term:\n",
    "        return res, tf.reduce_mean(final_state.resampling_correction)\n",
    "    return res, tf.constant(0.)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.optimizers.Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def run_one_step(smc, use_correction_term, init_state):\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(trainable_variables)\n",
    "        real_ll, correction = smc_routine(smc, init_state, use_correction_term)\n",
    "        loss = -(real_ll + correction)\n",
    "    grads_loss = tape.gradient(loss, trainable_variables)\n",
    "    return real_ll, grads_loss\n",
    "\n",
    "@tf.function\n",
    "def train_one_step(smc, use_correction_term):\n",
    "    real_ll, grads_loss = run_one_step(smc, use_correction_term, init_state)\n",
    "    optimizer.apply_gradients(zip(grads_loss, trainable_variables))\n",
    "    return -real_ll, grads_loss\n",
    "\n",
    "@tf.function\n",
    "def train_niter(smc, num_steps=100, use_correction_term=False, reset=True):\n",
    "    if reset:\n",
    "        reset_operations = [v.assign(init) for v, init in zip(trainable_variables, init_values)]\n",
    "    else:\n",
    "        reset_operations = []\n",
    "    loss_tensor_array = tf.TensorArray(dtype=tf.float32, size=num_steps, dynamic_size=False, element_shape=[])\n",
    "    grad_tensor_array = tf.TensorArray(dtype=tf.float32, size=num_steps, dynamic_size=False, element_shape=[])\n",
    "    time_tensor_array = tf.TensorArray(dtype=tf.float64, size=num_steps, dynamic_size=False, element_shape=[])\n",
    "    with tf.control_dependencies(reset_operations):\n",
    "        toc = tf.constant(0., dtype=tf.float64)\n",
    "        tic = tf.timestamp()\n",
    "        for step in tf.range(1, num_steps+1):\n",
    "            \n",
    "            tic_loss = tf.timestamp()\n",
    "            with tf.control_dependencies([tic_loss]):\n",
    "                loss, grads = train_one_step(smc, use_correction_term)\n",
    "            with tf.control_dependencies([loss]):\n",
    "                toc_loss = tf.timestamp()            \n",
    "            \n",
    "            elbo, _ = run_one_step(multinomial_smc, False, large_init_state)\n",
    "\n",
    "            toc += toc_loss - tic_loss\n",
    "            \n",
    "            max_grad = tf.reduce_max([tf.reduce_max(tf.abs(grad)) for grad in grads])\n",
    "            \n",
    "            tf.print('Step', step, '/', num_steps, ': ms per step= ', 1000. * toc / tf.cast(step, tf.float64), ': total compute time (s)= ', toc, 'Real Time elapsed (s): ', tf.timestamp()-tic, ', loss = ', loss, ', max abs grads = ', max_grad, end='\\r')\n",
    "            \n",
    "            loss_tensor_array = loss_tensor_array.write(step-1, -elbo)\n",
    "            grad_tensor_array = grad_tensor_array.write(step-1, max_grad)\n",
    "            time_tensor_array = time_tensor_array.write(step-1, toc)\n",
    "    return loss_tensor_array.stack(), grad_tensor_array.stack(), time_tensor_array.stack()\n",
    "\n",
    "@tf.function\n",
    "def train_total_time(smc, total_time, use_correction_term=False, reset=True):\n",
    "    if reset:\n",
    "        reset_operations = [v.assign(init) for v, init in zip(trainable_variables, init_values)]\n",
    "    else:\n",
    "        reset_operations = []\n",
    "    loss_tensor_array = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True, element_shape=[])\n",
    "    grad_tensor_array = tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True, element_shape=[])\n",
    "    time_tensor_array = tf.TensorArray(dtype=tf.float64, size=0, dynamic_size=True, element_shape=[])\n",
    "    with tf.control_dependencies(reset_operations):\n",
    "        toc = tf.constant(0., dtype=tf.float64)\n",
    "        tic = tf.timestamp()\n",
    "        step = tf.constant(1)\n",
    "        while toc < total_time:\n",
    "            \n",
    "            tic_loss = tf.timestamp()\n",
    "            with tf.control_dependencies([tic_loss]):\n",
    "                loss, grads = train_one_step(smc, use_correction_term)\n",
    "            with tf.control_dependencies([loss]):\n",
    "                toc_loss = tf.timestamp()   \n",
    "            elbo, _ = run_one_step(multinomial_smc, False, large_init_state)\n",
    "            \n",
    "            max_grad = tf.reduce_max([tf.reduce_max(tf.abs(grad)) for grad in grads])\n",
    "            loss_tensor_array = loss_tensor_array.write(step-1, -elbo)\n",
    "            grad_tensor_array = grad_tensor_array.write(step-1, max_grad)\n",
    "            time_tensor_array = time_tensor_array.write(step-1, toc)\n",
    "            step = step + 1\n",
    "\n",
    "            toc += toc_loss - tic_loss\n",
    "\n",
    "            tf.print('Compute Time elapsed (s): ', toc, 'Real Time elapsed (s): ', tf.timestamp()-tic, ', n_steps: ', step, ': ms per step= ', 1000. * toc / tf.cast(step, tf.float64), end='\\r')\n",
    "    return loss_tensor_array.stack(), grad_tensor_array.stack(), time_tensor_array.stack()\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def run_several(smc, n_times, use_correction_term=False):\n",
    "    loss_array = tf.TensorArray(dtype=tf.float32, size=n_times, dynamic_size=False, element_shape=[])\n",
    "    for i in tf.range(n_times):\n",
    "        real_ll, grads_loss = run_one_step(smc, use_correction_term, init_state)\n",
    "        loss_array = loss_array.write(i, real_ll)        \n",
    "        tf.print('Step: ', i+1, '/', n_times, end='\\r')\n",
    "    return loss_array.stack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 / 500 : ms per step=  182.12321472167969 : total compute time (s)=  91.061607360839844 Real Time elapsed (s):  185.93007397651672 , loss =  7884.6792 , max abs grads =  13.15663532\r"
     ]
    }
   ],
   "source": [
    "multinomial_ll_n_epochs, _, multinomial_time = train_niter(multinomial_smc, tf.constant(n_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  50 / 50\r"
     ]
    }
   ],
   "source": [
    "multinomial_ll_per_seed = run_several(multinomial_smc, tf.constant(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute Time elapsed (s):  30.096699237823486 Real Time elapsed (s):  60.753226041793823 , n_steps:  153 : ms per step=  196.71045253479403\r"
     ]
    }
   ],
   "source": [
    "multinomial_ll_total_time, _, _ = train_total_time(multinomial_smc, tf.constant(30, dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 / 500 : ms per step=  380.62903833389282 : total compute time (s)=  190.31451916694641 Real Time elapsed (s):  291.50849509239197 , loss =  7881.71582 , max abs grads =  11.3988018\r"
     ]
    }
   ],
   "source": [
    "reg_ll_n_epochs, _, reg_time = train_niter(regularized_smc, tf.constant(n_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  50 / 50\r"
     ]
    }
   ],
   "source": [
    "reg_ll_per_seed = run_several(regularized_smc, tf.constant(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute Time elapsed (s):  30.031550168991089 Real Time elapsed (s):  45.055738925933838 , n_steps:  80 : ms per step=  375.394377112388613\r"
     ]
    }
   ],
   "source": [
    "reg_ll_total_time, _, _ = train_total_time(regularized_smc, tf.constant(30, dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 500 / 500 : ms per step=  382.02610683441162 : total compute time (s)=  191.01305341720581 Real Time elapsed (s):  284.4905960559845 , loss =  7877.96436 , max abs grads =  11.21744062\r"
     ]
    }
   ],
   "source": [
    "corr_ll_n_epochs, _, corr_time = train_niter(corrected_smc, tf.constant(n_iter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step:  50 / 50\r"
     ]
    }
   ],
   "source": [
    "corr_ll_per_seed = run_several(corrected_smc, tf.constant(50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compute Time elapsed (s):  30.245247364044189 Real Time elapsed (s):  44.949915885925293 , n_steps:  78 : ms per step=  387.75958159031012\r"
     ]
    }
   ],
   "source": [
    "corr_ll_total_time, _, _ = train_total_time(corrected_smc, tf.constant(30, dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_log_likelihood' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-b5f172e1112b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreg_ll_n_epochs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'green'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorr_ll_n_epochs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'orange'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mtrue_log_likelihood\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./charts/'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vrnn_loss_per_epoch.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'true_log_likelihood' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(multinomial_ll_n_epochs.numpy(), color='blue')\n",
    "ax.plot(reg_ll_n_epochs.numpy(), color='green')\n",
    "ax.plot(corr_ll_n_epochs.numpy(), color='orange')\n",
    "ax.hlines(-true_log_likelihood, 0, n_iter)\n",
    "fig.savefig(os.path.join('./charts/', 'vrnn_loss_per_epoch.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.plot(np.linspace(0, 30, len(multinomial_ll_total_time.numpy())), multinomial_ll_total_time.numpy(), color='blue')\n",
    "ax.plot(np.linspace(0, 30, len(reg_ll_total_time.numpy())), reg_ll_total_time.numpy(), color='green')\n",
    "ax.plot(np.linspace(0, 30, len(corr_ll_total_time.numpy())), corr_ll_total_time.numpy(), color='orange')\n",
    "ax.hlines(-true_log_likelihood, 0, 30)\n",
    "fig.savefig(os.path.join('./charts/', 'vrnn_loss_per_second.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_loss_df = pd.Series(reg_ll_per_seed.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_loss_df = pd.Series(corr_ll_per_seed.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multinomial_loss_df = pd.Series(multinomial_ll_per_seed.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.concat([reg_loss_df, corr_loss_df, multinomial_loss_df], keys=['Regularized Transform', 'Variance Corrected Transform', 'Multinomial Resampling'], axis=1).describe().loc[['min', 'max', 'mean', 'std']].to_latex(float_format=\"%.3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_grad_df = pd.DataFrame(reg_grad_per_seed.numpy().std(0).reshape(-1, 3), columns = ['$\\mu_t$', r'$\\beta_t$', '$\\ln(\\sigma_t)$'])\n",
    "corr_grad_df = pd.DataFrame(corr_grad_per_seed.numpy().std(0).reshape(-1, 3), columns = ['$\\mu_t$', r'$\\beta_t$', '$\\ln(\\sigma_t)$'])\n",
    "multinomial_grad_df = pd.DataFrame(multinomial_grad_per_seed.numpy().std(0).reshape(-1, 3), columns = ['$\\mu_t$', r'$\\beta_t$', '$\\ln(\\sigma_t)$'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_df = pd.concat([reg_grad_df, corr_grad_df, multinomial_grad_df], keys=['Regularized Transform', 'Variance Corrected Transform', 'Multinomial Resampling'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grad_df.describe().loc[['min', 'max', 'mean', 'std']].to_latex(float_format=\"%.3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

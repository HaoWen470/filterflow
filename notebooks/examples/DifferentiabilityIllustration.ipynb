{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"../..\")\n",
    "\n",
    "import attr\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.set_visible_devices([], 'GPU') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from filterflow.base import State\n",
    "from filterflow.resampling.standard import SystematicResampler, StratifiedResampler, MultinomialResampler\n",
    "from filterflow.resampling.base import NoResampling\n",
    "from filterflow.resampling.differentiable import RegularisedTransform, CorrectedRegularizedTransform, PartiallyCorrectedRegularizedTransform\n",
    "from filterflow.resampling.differentiable.sliced import SVDSlicedTransform\n",
    "from filterflow.resampling.differentiable.optimized import OptimizedPointCloud\n",
    "from filterflow.resampling.differentiable.optimizer.sgd import SGD\n",
    "from filterflow.resampling.differentiable.ricatti.solver import PetkovSolver\n",
    "from filterflow.resampling.differentiable.loss.sliced_wasserstein.swd import SlicedWassersteinDistance\n",
    "from filterflow.resampling.differentiable.loss.regularized import SinkhornLoss\n",
    "from filterflow.resampling.differentiable.loss.sliced_wasserstein.utils import sqeuclidean, norm_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to demonstrate the differentiability issue encountered at resampling time. To do this we will compare functionals of the point cloud whilst changing a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(222)\n",
    "\n",
    "B = 1\n",
    "N = 25\n",
    "D = 1\n",
    "\n",
    "x = tf.random.normal([B, N, D], 0., 1.)\n",
    "y = tf.zeros(D)\n",
    "\n",
    "log_weights = tf.zeros([B, N]) - math.log(N)\n",
    "flags = tf.constant([True])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(state, observation, resampler):\n",
    "    rv = tfp.distributions.MultivariateNormalDiag(tf.zeros(D), tf.ones(D))\n",
    "    log_prob = rv.log_prob(observation-state.particles)\n",
    "    log_weights = log_prob - tf.reduce_logsumexp(log_prob, 1, keepdims=True)\n",
    "    state = attr.evolve(state, log_weights=log_weights, weights=tf.math.exp(log_weights))\n",
    "    state = resampler.apply(state, flags)\n",
    "    log_prob = rv.log_prob(observation-state.particles) + state.log_weights\n",
    "    return tf.reduce_logsumexp(log_prob)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_data = 150\n",
    "linspace = np.linspace(-0.5, 0.5, n_data).astype(np.float32)\n",
    "linspace_dataset = tf.data.Dataset.from_tensor_slices(linspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def get_data_no_reset_seed(linspace, resampler, x, y):\n",
    "    res = tf.TensorArray(dtype=tf.float32, dynamic_size=False, size=n_data)\n",
    "    grads = tf.TensorArray(dtype=tf.float32, dynamic_size=False, size=n_data)\n",
    "    i = tf.constant(0, dtype=tf.int64)\n",
    "    s = tf.constant(0., dtype=tf.float64)\n",
    "    total_tic = tf.timestamp()\n",
    "    for i, z_val in linspace_dataset.enumerate():\n",
    "        tic = tf.timestamp()\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(z_val)\n",
    "            z = z_val + tf.zeros(D)\n",
    "            state = State(x + z, log_weights, tf.math.exp(log_weights), tf.constant([0.]), None, None)\n",
    "            ll = log_likelihood(state, y, resampler)\n",
    "        ll_grad = tape.gradient(ll, z_val)\n",
    "        j = tf.cast(i, tf.int32)\n",
    "        res = res.write(j, ll)\n",
    "\n",
    "        grads = grads.write(j, ll_grad)\n",
    "        toc = tf.timestamp()\n",
    "        s = s + (toc - tic)\n",
    "        tf.print('Step', i+1, '/', n_data, ', seconds/iter =', s / tf.cast(i+1, tf.float64), end='\\r')\n",
    "    total_toc = tf.timestamp()\n",
    "\n",
    "    tf.print('Step', i+1, '/', n_data, ', total time (seconds) =', total_toc - total_tic)\n",
    "    return res.stack(), grads.stack()\n",
    "\n",
    "# do not decorate this. seed is being set\n",
    "def get_data(linspace, resampler, x, y, seed):\n",
    "    res = []\n",
    "    grads = []\n",
    "    for z_val in tqdm.tqdm(linspace):\n",
    "        z_ = tf.constant(z_val)\n",
    "        tf.random.set_seed(seed)\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(z_)\n",
    "            z = z_ + tf.zeros(D)\n",
    "            state = State(x + z, log_weights, tf.math.exp(log_weights), tf.constant([0.]), None, None)\n",
    "            ll = log_likelihood(state, y, resampler)\n",
    "        ll_grad = tape.gradient(ll, z)\n",
    "        res.append(ll.numpy().sum())\n",
    "        grads.append(ll_grad.numpy().sum())\n",
    "        \n",
    "    return res, grads\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "systematic = SystematicResampler()\n",
    "multinomial = MultinomialResampler()\n",
    "stratified = StratifiedResampler()\n",
    "no_resampling = NoResampling()\n",
    "\n",
    "epsilon = tf.constant(0.25)\n",
    "scaling = tf.constant(0.75)\n",
    "convergence_threshold = tf.constant(1e1)\n",
    "max_iter = tf.constant(500)\n",
    "\n",
    "regularized = RegularisedTransform(epsilon, scaling, max_iter, convergence_threshold)\n",
    "\n",
    "partially_corrected = PartiallyCorrectedRegularizedTransform(regularized)\n",
    "\n",
    "svd_sliced_resampler = SVDSlicedTransform(1)\n",
    "partially_corrected_svd = PartiallyCorrectedRegularizedTransform(svd_sliced_resampler)\n",
    "\n",
    "solver = PetkovSolver(n_iter=tf.constant(50))\n",
    "corrected_no_grad = CorrectedRegularizedTransform(epsilon, scaling, max_iter, convergence_threshold, ricatti_solver=solver, propagate_correction_gradient=False)\n",
    "corrected = CorrectedRegularizedTransform(epsilon, scaling, max_iter, convergence_threshold, ricatti_solver=solver, propagate_correction_gradient=True)\n",
    "\n",
    "sinkhorn_loss = SinkhornLoss(epsilon, symmetric=True, scaling=scaling, max_iter=tf.constant(100), convergence_threshold=convergence_threshold)\n",
    "sinkhorn_optimizer = SGD(sinkhorn_loss, 1., 50, 0.9)\n",
    "sinkhorn_optimized_cloud = OptimizedPointCloud(sinkhorn_optimizer, regularized)\n",
    "\n",
    "sliced_loss = SlicedWassersteinDistance(tf.constant(5), norm_1)\n",
    "sliced_optimizer = SGD(sliced_loss, 1., tf.constant(25), 0.9)\n",
    "sliced_optimized_cloud = OptimizedPointCloud(sliced_optimizer, systematic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function create_converted_entity_factory.<locals>.create_converted_entity.<locals>.tf__transport_1d.<locals>.where_one at 0x00000263ADE1A510> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weights = tf.random.uniform([B, N], 0., 1.)**2\n",
    "weights = weights / tf.reduce_sum(weights, -1)\n",
    "\n",
    "\n",
    "state = State(x, tf.math.log(weights), weights, tf.constant([0.]), None, None)\n",
    "svd_state = svd_sliced_resampler.apply(state, flags=flags)\n",
    "multinomial_state = multinomial.apply(state, flags=flags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ot\n",
    "np_x = x.numpy().squeeze()\n",
    "np_w = weights.numpy().squeeze()\n",
    "np_uniform = np.ones(N)/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(ncols=3, figsize=(16, 5))\n",
    "axes[0].hist(state.particles.numpy().squeeze(), bins=10, weights=state.weights.numpy().squeeze())\n",
    "axes[1].hist(svd_state.particles.numpy().squeeze(), bins=10, weights=svd_state.weights.numpy().squeeze())\n",
    "_ = axes[2].hist(multinomial_state.particles.numpy().squeeze(), bins=10, weights=multinomial_state.weights.numpy().squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\linalg\\linear_operator_diag.py:166: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Do not pass `graph_parents`.  They will  no longer be used.\n",
      "Step 150 / 150 , total time (seconds) = 0.28258204460144043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 150/150 [00:05<00:00, 29.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 150 / 150 , total time (seconds) = 0.86134600639343262\n",
      "WARNING:tensorflow:5 out of the last 12 calls to <function create_converted_entity_factory.<locals>.create_converted_entity.<locals>.tf__transport_1d.<locals>.where_one at 0x00000263B813F0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.\n",
      "[[[[0 0 0 ... 0 0 0]]]]\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.3535676 0.207181513 0.753882945 ... 0.854741812 1.06409085 1.05581212]]]]\n",
      "[[[0.3535676 0.207181513 0.753882945 ... 0.854741812 1.06409085 1.05581212]]]\n",
      "[[[[[-0.0158219673]\n",
      "   [0.00169203512]\n",
      "   [-0.0349325649]\n",
      "   ...\n",
      "   [-0.0353076272]\n",
      "   [-0.0202753376]\n",
      "   [0.0183384269]]]]]\n",
      "[[[[-0.0158219673]\n",
      "   [0.00169203512]\n",
      "   [-0.0349325649]\n",
      "   ...\n",
      "   [-0.0353076272]\n",
      "   [-0.0202753376]\n",
      "   [0.0183384269]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]iter = 0.058561086654663086\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.35245955 -0.0944582224 0.752322 ... 0.853410482 1.06331599 1.07208252]]]]\n",
      "[[[0.35245955 -0.0944582224 0.752322 ... 0.853410482 1.06331599 1.07208252]]]\n",
      "[[[[[-0.0155612091]\n",
      "   [0.00170479377]\n",
      "   [-0.0347834192]\n",
      "   ...\n",
      "   [-0.0352927968]\n",
      "   [-0.0208541118]\n",
      "   [0.0184084289]]]]]\n",
      "[[[[-0.0155612091]\n",
      "   [0.00170479377]\n",
      "   [-0.0347834192]\n",
      "   ...\n",
      "   [-0.0352927968]\n",
      "   [-0.0208541118]\n",
      "   [0.0184084289]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]iter = 0.057402610778808594\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.351398408 -0.0958364606 0.734287858 ... 0.835623205 1.04612613 1.0754298]]]]\n",
      "[[[0.351398408 -0.0958364606 0.734287858 ... 0.835623205 1.04612613 1.0754298]]]\n",
      "[[[[[-0.0153335249]\n",
      "   [0.00174033106]\n",
      "   [-0.034702003]\n",
      "   ...\n",
      "   [-0.0352852]\n",
      "   [-0.0214141756]\n",
      "   [0.0184131116]]]]]\n",
      "[[[[-0.0153335249]\n",
      "   [0.00174033106]\n",
      "   [-0.034702003]\n",
      "   ...\n",
      "   [-0.0352852]\n",
      "   [-0.0214141756]\n",
      "   [0.0184131116]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]iter = 0.055670420328776039\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.350320399 -0.0996653438 0.734124 ... 0.835706115 1.04681098 1.07630289]]]]\n",
      "[[[0.350320399 -0.0996653438 0.734124 ... 0.835706115 1.04681098 1.07630289]]]\n",
      "[[[[[-0.0151109407]\n",
      "   [0.00177641108]\n",
      "   [-0.034632206]\n",
      "   ...\n",
      "   [-0.035278514]\n",
      "   [-0.0219520871]\n",
      "   [0.017825827]]]]]\n",
      "[[[[-0.0151109407]\n",
      "   [0.00177641108]\n",
      "   [-0.034632206]\n",
      "   ...\n",
      "   [-0.035278514]\n",
      "   [-0.0219520871]\n",
      "   [0.017825827]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]iter = 0.054287314414978027\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.349238157 -0.0965275168 0.73394537 ... 0.835776865 1.05447626 1.08415151]]]]\n",
      "[[[0.349238157 -0.0965275168 0.73394537 ... 0.835776865 1.05447626 1.08415151]]]\n",
      "[[[[[-0.0148869473]\n",
      "   [0.00181309448]\n",
      "   [-0.0345595032]\n",
      "   ...\n",
      "   [-0.0352737159]\n",
      "   [-0.0224687066]\n",
      "   [0.0171994194]]]]]\n",
      "[[[[-0.0148869473]\n",
      "   [0.00181309448]\n",
      "   [-0.0345595032]\n",
      "   ...\n",
      "   [-0.0352737159]\n",
      "   [-0.0224687066]\n",
      "   [0.0171994194]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]iter = 0.053026247024536136\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.34814924 -0.100420713 0.733748436 ... 0.835831761 1.0551182 1.08497167]]]]\n",
      "[[[0.34814924 -0.100420713 0.733748436 ... 0.835831761 1.0551182 1.08497167]]]\n",
      "[[[[[-0.0146615542]\n",
      "   [0.00185038045]\n",
      "   [-0.0344837606]\n",
      "   ...\n",
      "   [-0.0352706648]\n",
      "   [-0.0229641721]\n",
      "   [0.0165337566]]]]]\n",
      "[[[[-0.0146615542]\n",
      "   [0.00185038045]\n",
      "   [-0.0344837606]\n",
      "   ...\n",
      "   [-0.0352706648]\n",
      "   [-0.0229641721]\n",
      "   [0.0165337566]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]iter = 0.051853020985921226\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.347055912 -0.0954653 0.733536959 ... 0.835874915 1.05575871 1.08578575]]]]\n",
      "[[[0.347055912 -0.0954653 0.733536959 ... 0.835874915 1.05575871 1.08578575]]]\n",
      "[[[[[-0.0144348759]\n",
      "   [0.00188828085]\n",
      "   [-0.0344049968]\n",
      "   ...\n",
      "   [-0.03526932]\n",
      "   [-0.0234387591]\n",
      "   [0.0158287715]]]]]\n",
      "[[[[-0.0144348759]\n",
      "   [0.00188828085]\n",
      "   [-0.0344049968]\n",
      "   ...\n",
      "   [-0.03526932]\n",
      "   [-0.0234387591]\n",
      "   [0.0158287715]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]iter = 0.051037447793143134\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.34595567 -0.0993261933 0.733307 ... 0.83590126 1.05639172 1.08658743]]]]\n",
      "[[[0.34595567 -0.0993261933 0.733307 ... 0.83590126 1.05639172 1.08658743]]]\n",
      "[[[[[-0.0142068639]\n",
      "   [0.00192679069]\n",
      "   [-0.0343228839]\n",
      "   ...\n",
      "   [-0.0352693684]\n",
      "   [-0.0238925125]\n",
      "   [0.0150842955]]]]]\n",
      "[[[[-0.0142068639]\n",
      "   [0.00192679069]\n",
      "   [-0.0343228839]\n",
      "   ...\n",
      "   [-0.0352693684]\n",
      "   [-0.0238925125]\n",
      "   [0.0150842955]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]iter = 0.050278633832931519\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.344849229 -0.103192091 0.73306185 ... 0.835915804 1.05702472 1.08738458]]]]\n",
      "[[[0.344849229 -0.103192091 0.73306185 ... 0.835915804 1.05702472 1.08738458]]]\n",
      "[[[[[-0.0139777204]\n",
      "   [0.00196593185]\n",
      "   [-0.0342377275]\n",
      "   ...\n",
      "   [-0.0352711417]\n",
      "   [-0.0243258923]\n",
      "   [0.0143004721]]]]]\n",
      "[[[[-0.0139777204]\n",
      "   [0.00196593185]\n",
      "   [-0.0342377275]\n",
      "   ...\n",
      "   [-0.0352711417]\n",
      "   [-0.0243258923]\n",
      "   [0.0143004721]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]iter = 0.049695014953613281\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.343724608 -0.0729628801 0.73277241 ... 0.83588326 1.05760968 1.12221253]]]]\n",
      "[[[0.343724608 -0.0729628801 0.73277241 ... 0.83588326 1.05760968 1.12221253]]]\n",
      "[[[[[-0.013746785]\n",
      "   [0.00200560433]\n",
      "   [-0.0341476761]\n",
      "   ...\n",
      "   [-0.0352725945]\n",
      "   [-0.0246718898]\n",
      "   [0.0134764891]]]]]\n",
      "[[[[-0.013746785]\n",
      "   [0.00200560433]\n",
      "   [-0.0341476761]\n",
      "   ...\n",
      "   [-0.0352725945]\n",
      "   [-0.0246718898]\n",
      "   [0.0134764891]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]/iter = 0.05022132396697998\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.34258765 -0.06948632 0.732456625 ... 0.843129337 1.06548226 1.13026297]]]]\n",
      "[[[0.34258765 -0.06948632 0.732456625 ... 0.843129337 1.06548226 1.13026297]]]\n",
      "[[[[[-0.013514623]\n",
      "   [0.00204588776]\n",
      "   [-0.0340299904]\n",
      "   ...\n",
      "   [-0.035310559]\n",
      "   [-0.0249795243]\n",
      "   [0.0126129966]]]]]\n",
      "[[[[-0.013514623]\n",
      "   [0.00204588776]\n",
      "   [-0.0340299904]\n",
      "   ...\n",
      "   [-0.035310559]\n",
      "   [-0.0249795243]\n",
      "   [0.0126129966]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]/iter = 0.050361741672862663\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.341449022 -0.0734096766 0.732132196 ... 0.842956305 1.06594527 1.13089967]]]]\n",
      "[[[0.341449022 -0.0734096766 0.732132196 ... 0.842956305 1.06594527 1.13089967]]]\n",
      "[[[[[-0.0132814599]\n",
      "   [0.00208680867]\n",
      "   [-0.0338572077]\n",
      "   ...\n",
      "   [-0.0354276523]\n",
      "   [-0.0252682418]\n",
      "   [0.0117100943]]]]]\n",
      "[[[[-0.0132814599]\n",
      "   [0.00208680867]\n",
      "   [-0.0338572077]\n",
      "   ...\n",
      "   [-0.0354276523]\n",
      "   [-0.0252682418]\n",
      "   [0.0117100943]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]/iter = 0.050360520680745445\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.34030503 -0.0773209929 0.731796265 ... 0.842774332 1.0664115 1.13153589]]]]\n",
      "[[[0.34030503 -0.0773209929 0.731796265 ... 0.842774332 1.0664115 1.13153589]]]\n",
      "[[[[[-0.0130473953]\n",
      "   [0.00212837965]\n",
      "   [-0.0336854942]\n",
      "   ...\n",
      "   [-0.0355415605]\n",
      "   [-0.0255384501]\n",
      "   [0.0107679553]]]]]\n",
      "[[[[-0.0130473953]\n",
      "   [0.00212837965]\n",
      "   [-0.0336854942]\n",
      "   ...\n",
      "   [-0.0355415605]\n",
      "   [-0.0255384501]\n",
      "   [0.0107679553]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]/iter = 0.050437028591449447\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.339158 -0.0812141895 0.731452286 ... 0.842586339 1.06688333 1.13217509]]]]\n",
      "[[[0.339158 -0.0812141895 0.731452286 ... 0.842586339 1.06688333 1.13217509]]]\n",
      "[[[[[-0.0128124859]\n",
      "   [0.00217061047]\n",
      "   [-0.0335147306]\n",
      "   ...\n",
      "   [-0.0356522091]\n",
      "   [-0.0257904]\n",
      "   [0.00978660583]]]]]\n",
      "[[[[-0.0128124859]\n",
      "   [0.00217061047]\n",
      "   [-0.0335147306]\n",
      "   ...\n",
      "   [-0.0356522091]\n",
      "   [-0.0257904]\n",
      "   [0.00978660583]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]/iter = 0.050333942685808451\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.338008106 -0.085085392 0.731100798 ... 0.84239316 1.06736183 1.13281691]]]]\n",
      "[[[0.338008106 -0.085085392 0.731100798 ... 0.84239316 1.06736183 1.13281691]]]\n",
      "[[[[[-0.0125767523]\n",
      "   [0.00221350719]\n",
      "   [-0.0333448648]\n",
      "   ...\n",
      "   [-0.0357595645]\n",
      "   [-0.0260243118]\n",
      "   [0.00876611564]]]]]\n",
      "[[[[-0.0125767523]\n",
      "   [0.00221350719]\n",
      "   [-0.0333448648]\n",
      "   ...\n",
      "   [-0.0357595645]\n",
      "   [-0.0260243118]\n",
      "   [0.00876611564]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]/iter = 0.050279283523559572\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.336854935 -0.0888971686 0.730741858 ... 0.842194617 1.06784654 1.13349509]]]]\n",
      "[[[0.336854935 -0.0888971686 0.730741858 ... 0.842194617 1.06784654 1.13349509]]]\n",
      "[[[[[-0.0123402337]\n",
      "   [0.00225707027]\n",
      "   [-0.0331758372]\n",
      "   ...\n",
      "   [-0.0358635299]\n",
      "   [-0.0262404531]\n",
      "   [0.00770658627]]]]]\n",
      "[[[[-0.0123402337]\n",
      "   [0.00225707027]\n",
      "   [-0.0331758372]\n",
      "   ...\n",
      "   [-0.0358635299]\n",
      "   [-0.0262404531]\n",
      "   [0.00770658627]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]/iter = 0.050281897187232971\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.335699379 -0.092710495 0.73037684 ... 0.841992319 1.06833947 1.1341449]]]]\n",
      "[[[0.335699379 -0.092710495 0.73037684 ... 0.841992319 1.06833947 1.1341449]]]\n",
      "[[[[[-0.0121029904]\n",
      "   [0.00230130949]\n",
      "   [-0.0330076143]\n",
      "   ...\n",
      "   [-0.0359640531]\n",
      "   [-0.0264390595]\n",
      "   [0.00660814345]]]]]\n",
      "[[[[-0.0121029904]\n",
      "   [0.00230130949]\n",
      "   [-0.0330076143]\n",
      "   ...\n",
      "   [-0.0359640531]\n",
      "   [-0.0264390595]\n",
      "   [0.00660814345]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]/iter = 0.050377971985760855\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.334491253 0.0281131864 0.729898691 ... 0.841662705 1.06868398 1.13463318]]]]\n",
      "[[[0.334491253 0.0281131864 0.729898691 ... 0.841662705 1.06868398 1.13463318]]]\n",
      "[[[[[-0.0118632969]\n",
      "   [0.00234589167]\n",
      "   [-0.0328353383]\n",
      "   ...\n",
      "   [-0.0360557735]\n",
      "   [-0.0266164895]\n",
      "   [0.00638458319]]]]]\n",
      "[[[[-0.0118632969]\n",
      "   [0.00234589167]\n",
      "   [-0.0328353383]\n",
      "   ...\n",
      "   [-0.0360557735]\n",
      "   [-0.0266164895]\n",
      "   [0.00638458319]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]/iter = 0.050466418266296387\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.333245575 0.042827785 0.729337633 ... 0.841240287 1.08815742 1.15424037]]]]\n",
      "[[[0.333245575 0.042827785 0.729337633 ... 0.841240287 1.08815742 1.15424037]]]\n",
      "[[[[[-0.0116217611]\n",
      "   [0.00239088829]\n",
      "   [-0.0326603204]\n",
      "   ...\n",
      "   [-0.0361400358]\n",
      "   [-0.0269725285]\n",
      "   [0.00669589]]]]]\n",
      "[[[[-0.0116217611]\n",
      "   [0.00239088829]\n",
      "   [-0.0326603204]\n",
      "   ...\n",
      "   [-0.0361400358]\n",
      "   [-0.0269725285]\n",
      "   [0.00669589]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]/iter = 0.050377456765425835\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.331991971 0.038215816 0.728759348 ... 0.840800941 1.08836973 1.15458226]]]]\n",
      "[[[0.331991971 0.038215816 0.728759348 ... 0.840800941 1.08836973 1.15458226]]]\n",
      "[[[[[-0.0113795185]\n",
      "   [0.00243651634]\n",
      "   [-0.0324855074]\n",
      "   ...\n",
      "   [-0.036219988]\n",
      "   [-0.0275526084]\n",
      "   [0.0069636316]]]]]\n",
      "[[[[-0.0113795185]\n",
      "   [0.00243651634]\n",
      "   [-0.0324855074]\n",
      "   ...\n",
      "   [-0.036219988]\n",
      "   [-0.0275526084]\n",
      "   [0.0069636316]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]/iter = 0.050401222705841062\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.330734909 0.049833715 0.728174269 ... 0.84035641 1.10480046 1.171139]]]]\n",
      "[[[0.330734909 0.049833715 0.728174269 ... 0.84035641 1.10480046 1.171139]]]\n",
      "[[[[[-0.0111367451]\n",
      "   [0.00248280889]\n",
      "   [-0.0323113278]\n",
      "   ...\n",
      "   [-0.0362806767]\n",
      "   [-0.0281127058]\n",
      "   [0.00718743075]]]]]\n",
      "[[[[-0.0111367451]\n",
      "   [0.00248280889]\n",
      "   [-0.0323113278]\n",
      "   ...\n",
      "   [-0.0362806767]\n",
      "   [-0.0281127058]\n",
      "   [0.00718743075]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]/iter = 0.050403311139061338\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.329470754 0.0451974869 0.727573693 ... 0.839896619 1.10494494 1.1714052]]]]\n",
      "[[[0.329470754 0.0451974869 0.727573693 ... 0.839896619 1.10494494 1.1714052]]]\n",
      "[[[[[-0.0108933393]\n",
      "   [0.00252973801]\n",
      "   [-0.0321372598]\n",
      "   ...\n",
      "   [-0.0361761265]\n",
      "   [-0.0286526568]\n",
      "   [0.00736672897]]]]]\n",
      "[[[[-0.0108933393]\n",
      "   [0.00252973801]\n",
      "   [-0.0321372598]\n",
      "   ...\n",
      "   [-0.0361761265]\n",
      "   [-0.0286526568]\n",
      "   [0.00736672897]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]/iter = 0.050391153855757279\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.328203261 0.040587306 0.726967931 ... 0.83943367 1.10509753 1.17167664]]]]\n",
      "[[[0.328203261 0.040587306 0.726967931 ... 0.83943367 1.10509753 1.17167664]]]\n",
      "[[[[[-0.0106495032]\n",
      "   [0.00257734302]\n",
      "   [-0.0319638439]\n",
      "   ...\n",
      "   [-0.0360722579]\n",
      "   [-0.0291731674]\n",
      "   [0.00750117796]]]]]\n",
      "[[[[-0.0106495032]\n",
      "   [0.00257734302]\n",
      "   [-0.0319638439]\n",
      "   ...\n",
      "   [-0.0360722579]\n",
      "   [-0.0291731674]\n",
      "   [0.00750117796]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]/iter = 0.050490804340528404\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.32707262 0.0531774163 0.707132518 ... 0.81973815 1.08601689 1.18907499]]]]\n",
      "[[[0.32707262 0.0531774163 0.707132518 ... 0.81973815 1.08601689 1.18907499]]]\n",
      "[[[[[-0.0104535287]\n",
      "   [0.00262552104]\n",
      "   [-0.0317876637]\n",
      "   ...\n",
      "   [-0.0359674655]\n",
      "   [-0.0296732727]\n",
      "   [0.00725647341]]]]]\n",
      "[[[[-0.0104535287]\n",
      "   [0.00262552104]\n",
      "   [-0.0317876637]\n",
      "   ...\n",
      "   [-0.0359674655]\n",
      "   [-0.0296732727]\n",
      "   [0.00725647341]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]/iter = 0.050540645917256675\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.326129854 0.0486359596 0.706473231 ... 0.819218695 1.0861187 1.18929076]]]]\n",
      "[[[0.326129854 0.0486359596 0.706473231 ... 0.819218695 1.0861187 1.18929076]]]\n",
      "[[[[[-0.0103224358]\n",
      "   [0.00267433724]\n",
      "   [-0.0316086113]\n",
      "   ...\n",
      "   [-0.0358625688]\n",
      "   [-0.0301538836]\n",
      "   [0.00665144855]]]]]\n",
      "[[[[-0.0103224358]\n",
      "   [0.00267433724]\n",
      "   [-0.0316086113]\n",
      "   ...\n",
      "   [-0.0358625688]\n",
      "   [-0.0301538836]\n",
      "   [0.00665144855]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]/iter = 0.050464744567871096\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.325182438 0.0441368818 0.705810785 ... 0.818698 1.08623099 1.18951488]]]]\n",
      "[[[0.325182438 0.0441368818 0.705810785 ... 0.818698 1.08623099 1.18951488]]]\n",
      "[[[[[-0.0101924865]\n",
      "   [0.00272383983]\n",
      "   [-0.0314298458]\n",
      "   ...\n",
      "   [-0.0357581861]\n",
      "   [-0.0306158084]\n",
      "   [0.00599786453]]]]]\n",
      "[[[[-0.0101924865]\n",
      "   [0.00272383983]\n",
      "   [-0.0314298458]\n",
      "   ...\n",
      "   [-0.0357581861]\n",
      "   [-0.0306158084]\n",
      "   [0.00599786453]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]/iter = 0.050477486390333906\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.324232399 0.0396875143 0.705148458 ... 0.818179369 1.08635604 1.18975008]]]]\n",
      "[[[0.324232399 0.0396875143 0.705148458 ... 0.818179369 1.08635604 1.18975008]]]\n",
      "[[[[[-0.0100637339]\n",
      "   [0.00277403113]\n",
      "   [-0.0312513709]\n",
      "   ...\n",
      "   [-0.0356542356]\n",
      "   [-0.0310593285]\n",
      "   [0.00529534416]]]]]\n",
      "[[[[-0.0100637339]\n",
      "   [0.00277403113]\n",
      "   [-0.0312513709]\n",
      "   ...\n",
      "   [-0.0356542356]\n",
      "   [-0.0310593285]\n",
      "   [0.00529534416]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]/iter = 0.050685909059312612\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.323276758 0.0352896452 0.704482436 ... 0.81765908 1.08649111 1.18999374]]]]\n",
      "[[[0.323276758 0.0352896452 0.704482436 ... 0.81765908 1.08649111 1.18999374]]]\n",
      "[[[[[-0.00993607]\n",
      "   [0.00282491976]\n",
      "   [-0.0310731735]\n",
      "   ...\n",
      "   [-0.0355506614]\n",
      "   [-0.0314846896]\n",
      "   [0.00454356847]]]]]\n",
      "[[[[-0.00993607]\n",
      "   [0.00282491976]\n",
      "   [-0.0310731735]\n",
      "   ...\n",
      "   [-0.0355506614]\n",
      "   [-0.0314846896]\n",
      "   [0.00454356847]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]/iter = 0.050684341362544467\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.322316885 0.0309499502 0.703814447 ... 0.817138731 1.08663774 1.19024754]]]]\n",
      "[[[0.322316885 0.0309499502 0.703814447 ... 0.817138731 1.08663774 1.19024754]]]\n",
      "[[[[[-0.0098095471]\n",
      "   [0.00287650619]\n",
      "   [-0.0308952481]\n",
      "   ...\n",
      "   [-0.0354473889]\n",
      "   [-0.0318921506]\n",
      "   [0.00374220032]]]]]\n",
      "[[[[-0.0098095471]\n",
      "   [0.00287650619]\n",
      "   [-0.0308952481]\n",
      "   ...\n",
      "   [-0.0354473889]\n",
      "   [-0.0318921506]\n",
      "   [0.00374220032]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]/iter = 0.050660018263192011\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.321343422 0.0588053465 0.703122079 ... 0.816591382 1.08675814 1.22260022]]]]\n",
      "[[[0.321343422 0.0588053465 0.703122079 ... 0.816591382 1.08675814 1.22260022]]]\n",
      "[[[[[-0.00968387444]\n",
      "   [0.00292868377]\n",
      "   [-0.0307164416]\n",
      "   ...\n",
      "   [-0.0353430323]\n",
      "   [-0.0322808027]\n",
      "   [0.00289082946]]]]]\n",
      "[[[[-0.00968387444]\n",
      "   [0.00292868377]\n",
      "   [-0.0307164416]\n",
      "   ...\n",
      "   [-0.0353430323]\n",
      "   [-0.0322808027]\n",
      "   [0.00289082946]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]/iter = 0.050678054491678871\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.320349455 0.0664203763 0.702394068 ... 0.816005468 1.08683944 1.22283459]]]]\n",
      "[[[0.320349455 0.0664203763 0.702394068 ... 0.816005468 1.08683944 1.22283459]]]\n",
      "[[[[[-0.00955884624]\n",
      "   [0.00298142596]\n",
      "   [-0.0305364951]\n",
      "   ...\n",
      "   [-0.0352372751]\n",
      "   [-0.0326505825]\n",
      "   [0.00198928895]]]]]\n",
      "[[[[-0.00955884624]\n",
      "   [0.00298142596]\n",
      "   [-0.0305364951]\n",
      "   ...\n",
      "   [-0.0352372751]\n",
      "   [-0.0326505825]\n",
      "   [0.00198928895]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]/iter = 0.050636860632127328\n",
      "[[[0 0 0 ... 0 0 0]]]\n",
      "[[[[0.319351614 0.062381804 0.701664329 ... 0.815419 1.08693051 1.22307789]]]]\n",
      "[[[0.319351614 0.062381804 0.701664329 ... 0.815419 1.08693051 1.22307789]]]\n",
      "[[[[[-0.00943496637]\n",
      "   [0.00303485757]\n",
      "   [-0.0303567424]\n",
      "   ...\n",
      "   [-0.0351315215]\n",
      "   [-0.0330030918]\n",
      "   [0.00103750196]]]]]\n",
      "[[[[-0.00943496637]\n",
      "   [0.00303485757]\n",
      "   [-0.0303567424]\n",
      "   ...\n",
      "   [-0.0351315215]\n",
      "   [-0.0330030918]\n",
      "   [0.00103750196]]]]\n",
      "[[[[0 0 0 ... 0 0 0]]]]/iter = 0.050594642758369446\n"
     ]
    }
   ],
   "source": [
    "no_resampling_data, no_resampling_grad = get_data_no_reset_seed(linspace, no_resampling, x, y)\n",
    "# systematic_data, systematic_grad = get_data(linspace, systematic, x, y, 42)\n",
    "multinomial_data, multinomial_grad = get_data(linspace, multinomial, x, y, 51)\n",
    "# stratified_data, stratified_grad = get_data(linspace, stratified, x, y, 44)\n",
    "\n",
    "regularized_data, regularized_grad = get_data_no_reset_seed(linspace, regularized, x, y)\n",
    "# corrected_no_grad_data, corrected_no_grad_grad = get_data_no_reset_seed(linspace, corrected_no_grad, x, y)\n",
    "# corrected_data, corrected_grad = get_data_no_reset_seed(linspace, corrected, x, y)\n",
    "svd_data, svd_grad = get_data_no_reset_seed(linspace, svd_sliced_resampler, x, y)\n",
    "partially_corrected_svd_data, partially_corrected_svd_grad = get_data_no_reset_seed(linspace, partially_corrected_svd, x, y)\n",
    "# partially_corrected_data, partially_corrected_grad = get_data_no_reset_seed(linspace, partially_corrected, x, y)\n",
    "# sliced_optimized_data, sliced_optimized_grad = get_data_no_reset_seed(linspace, sliced_optimized_cloud, x, y)\n",
    "# sinkhorn_optimized_data, sinkhorn_optimized_grad = get_data_no_reset_seed(linspace, sinkhorn_optimized_cloud, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(linspace, svd_data, label='svd_data')\n",
    "plt.plot(linspace, partially_corrected_svd_data, label='partially_corrected_svd_data')\n",
    "plt.plot(linspace, regularized_data, label='regularized_data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(linspace, svd_grad, label='svd_data')\n",
    "plt.step(linspace, partially_corrected_svd_grad, label='partially_corrected_svd_data')\n",
    "plt.step(linspace, regularized_grad, label='regularized_data')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(15, 5), sharex=True, sharey=True)\n",
    "axes[0].plot(linspace, no_resampling_data, label='no resampling', linestyle='--', color='k')\n",
    "axes[1].plot(linspace, no_resampling_data, label='no resampling', linestyle='--', color='k')\n",
    "axes[0].step(linspace, systematic_data, label='systematic', alpha=0.75)\n",
    "axes[0].step(linspace, multinomial_data, label='multinomial', alpha=0.75)\n",
    "axes[0].step(linspace, stratified_data, label='stratified', alpha=0.75)\n",
    "axes[1].plot(linspace, regularized_data, label='regularized')\n",
    "axes[1].plot(linspace, corrected_data, label='corrected')\n",
    "axes[1].plot(linspace, corrected_no_grad_data, label='corrected_no_grad')\n",
    "axes[1].plot(linspace, partially_corrected_data, label='partially_corrected_data')\n",
    "axes[1].plot(linspace, partially_corrected_svd_data, label='partially_corrected_svd_data')\n",
    "axes[1].plot(linspace, svd_data, label='svd_data')\n",
    "axes[1].plot(linspace, sliced_optimized_data, label='sliced_optimized')\n",
    "axes[1].plot(linspace, sinkhorn_optimized_data, label='sinkhorn_optimized')\n",
    "_ = axes[0].legend(), axes[1].legend()\n",
    "fig.savefig(os.path.join('./charts/', 'differentiability_illustration_likelihood.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(15, 5), sharex=True, sharey=False)\n",
    "axes[0].step(linspace, no_resampling_grad, label='no resampling', linestyle='--', color='k')\n",
    "axes[1].step(linspace, no_resampling_grad, label='no resampling', linestyle='--', color='k')\n",
    "axes[0].step(linspace, systematic_grad, label='systematic', alpha=0.75)\n",
    "axes[0].step(linspace, multinomial_grad, label='multinomial', alpha=0.75)\n",
    "axes[0].step(linspace, stratified_grad, label='stratified', alpha=0.75)\n",
    "axes[1].plot(linspace, regularized_grad, label='regularized')\n",
    "axes[1].plot(linspace, corrected_grad, label='corrected')\n",
    "axes[1].plot(linspace, corrected_no_grad_grad, label='corrected_no_grad')\n",
    "axes[1].plot(linspace, partially_corrected_grad, label='partially_corrected_data')\n",
    "axes[1].plot(linspace, sliced_optimized_data, label='sliced_optimized')\n",
    "axes[1].step(linspace, svd_grad, label='svd_data')\n",
    "axes[1].step(linspace, partially_corrected_svd_grad, label='partially_corrected_svd_data')\n",
    "# axes[1].plot(linspace, sliced_optimized_data, label='sliced_optimized')\n",
    "axes[1].plot(linspace, sinkhorn_optimized_grad, label='sinkhorn_optimized')\n",
    "_ = axes[0].legend(), axes[1].legend()\n",
    "fig.savefig(os.path.join('./charts/', 'differentiability_illustration_gradient.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "a = tf.squeeze(x)\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(a)\n",
    "    b, idx = tf.math.top_k(a, k=N)\n",
    "tape.gradient(b[...], a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.scatter_nd(idx, [1.], a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.scatter_nd?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.math.top_k(a, k=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
